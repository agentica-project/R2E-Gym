diff --git a/comprehensive_test.py b/comprehensive_test.py
new file mode 100644
index 000000000..5b1fc9769
--- /dev/null
+++ b/comprehensive_test.py
@@ -0,0 +1,38 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+def test_with_varying_bins_and_data():
+    # Test with different numbers of bins and data points
+    test_cases = [
+        # (data_points, n_bins)
+        (6, 2),    # Fewer bins than data points
+        (6, 3),    # Fewer bins than data points
+        (6, 4),    # Fewer bins than data points
+        (6, 5),    # Almost as many bins as data points
+        (6, 6),    # As many bins as data points
+        (10, 5),   # More data points than bins
+        (10, 9),   # Almost as many bins as data points
+        (10, 10),  # As many bins as data points
+    ]
+
+    for i, (n_points, n_bins) in enumerate(test_cases):
+        # Create random data
+        np.random.seed(42)  # For reproducibility
+        X = np.random.rand(n_points, 1) * 10  # Random values between 0 and 10
+
+        print(f"Test case {i+1}: {n_points} data points, {n_bins} bins")
+        try:
+            est = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans', encode='ordinal')
+            Xt = est.fit_transform(X)
+            print(f"  Success! Unique bins: {np.unique(Xt, axis=0).shape[0]}")
+            # Check if bin edges are sorted
+            is_sorted = np.all(np.diff(est.bin_edges_[0]) >= 0)
+            print(f"  Bin edges sorted: {is_sorted}")
+        except Exception as e:
+            print(f"  Error: {e}")
+        print()
+
+if __name__ == "__main__":
+    print("Testing KBinsDiscretizer with varying numbers of bins and data points")
+    print("===================================================================")
+    test_with_varying_bins_and_data()
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..2de04fc0d
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,23 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+# Create the test data from the issue description
+X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
+
+# Try with 5 bins (as mentioned in the issue)
+print("Testing with 5 bins:")
+try:
+    est = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')
+    Xt = est.fit_transform(X)
+    print("Success! Transform result:", Xt.ravel())
+except ValueError as e:
+    print("Error:", e)
+
+# Also try with 3 bins (which works in the test case)
+print("\nTesting with 3 bins:")
+try:
+    est = KBinsDiscretizer(n_bins=3, strategy='kmeans', encode='ordinal')
+    Xt = est.fit_transform(X)
+    print("Success! Transform result:", Xt.ravel())
+except ValueError as e:
+    print("Error:", e)
\ No newline at end of file
diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py
index dd969c12b..f77e57a9c 100644
--- a/sklearn/preprocessing/_discretization.py
+++ b/sklearn/preprocessing/_discretization.py
@@ -1,7 +1,7 @@
 # -*- coding: utf-8 -*-
 
 # Author: Henry Lin <hlin117@gmail.com>
-#         Tom Dupré la Tour
+#         Tom DuprÃ© la Tour
 
 # License: BSD
 
@@ -175,6 +175,9 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):
                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5
                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]
 
+                # Ensure bin edges are sorted for np.digitize
+                bin_edges[jj] = np.sort(bin_edges[jj])
+
         self.bin_edges_ = bin_edges
         self.n_bins_ = n_bins
 
