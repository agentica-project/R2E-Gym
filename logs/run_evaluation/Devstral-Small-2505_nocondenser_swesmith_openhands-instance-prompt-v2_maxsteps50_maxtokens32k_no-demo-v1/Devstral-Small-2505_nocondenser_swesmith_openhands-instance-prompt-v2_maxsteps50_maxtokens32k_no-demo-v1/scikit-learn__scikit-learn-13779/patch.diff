diff --git a/comprehensive_test.py b/comprehensive_test.py
new file mode 100644
index 000000000..85972692a
--- /dev/null
+++ b/comprehensive_test.py
@@ -0,0 +1,58 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.ensemble import VotingClassifier
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier
+from sklearn.svm import SVC
+
+# Load data
+X, y = load_iris(return_X_y=True)
+
+# Test 1: Basic case - one estimator set to None
+print("\nTest 1: Basic case - one estimator set to None")
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+voter.set_params(lr=None)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+print("Test 1: PASSED")
+
+# Test 2: Multiple estimators set to None
+print("\nTest 2: Multiple estimators set to None")
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier()),
+                ('svc', SVC(probability=True))]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+voter.set_params(lr=None, svc=None)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+print("Test 2: PASSED")
+
+# Test 3: All estimators set to None (should raise ValueError)
+print("\nTest 3: All estimators set to None (should raise ValueError)")
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+voter.set_params(lr=None, rf=None)
+try:
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Test 3: FAILED - Should have raised ValueError")
+except ValueError as e:
+    print(f"Test 3: PASSED - Correctly raised ValueError: {e}")
+
+# Test 4: Different sample_weight formats
+print("\nTest 4: Different sample_weight formats")
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+voter.set_params(lr=None)
+# Test with array-like sample_weight
+voter.fit(X, y, sample_weight=np.ones(y.shape) * 0.5)
+print("Test 4: PASSED")
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..7a0d87856
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,30 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.ensemble import VotingClassifier
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier
+
+# Load data
+X, y = load_iris(return_X_y=True)
+
+# Create voting classifier
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+
+# Fit with sample weights - this should work
+print("Fitting with all estimators (should work)")
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+
+# Set one estimator to None
+print("Setting 'lr' estimator to None")
+voter.set_params(lr=None)
+
+# Try to fit again with sample weights - this will fail
+print("Fitting with one None estimator (will fail)")
+try:
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Success! The issue is fixed.")
+except AttributeError as e:
+    print(f"Failed with error: {e}")
\ No newline at end of file
diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py
index 7afa7180c..13accdcec 100644
--- a/sklearn/ensemble/voting.py
+++ b/sklearn/ensemble/voting.py
@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):
 
         if sample_weight is not None:
             for name, step in self.estimators:
-                if not has_fit_parameter(step, 'sample_weight'):
+                if step is not None and not has_fit_parameter(step, 'sample_weight'):
                     raise ValueError('Underlying estimator \'%s\' does not'
                                      ' support sample weights.' % name)
 
