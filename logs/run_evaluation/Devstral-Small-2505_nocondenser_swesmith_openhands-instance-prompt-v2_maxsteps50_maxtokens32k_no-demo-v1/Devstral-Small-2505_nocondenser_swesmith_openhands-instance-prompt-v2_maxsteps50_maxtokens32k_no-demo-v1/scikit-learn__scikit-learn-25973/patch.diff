diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..b6703cba4
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,75 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut, KFold
+from sklearn.linear_model import LogisticRegression
+from sklearn.svm import SVC
+
+import numpy as np
+
+def test_with_cv(cv_name, cv_obj, splits=None):
+    print(f"\nTesting with {cv_name}:")
+
+    # Create a dataset
+    X, y = make_classification()
+
+    # Create groups for group-based cross-validation if needed
+    groups = None
+    if 'group' in cv_name.lower():
+        groups = np.zeros_like(y, dtype=int)
+        groups[y.size//2:] = 1
+        if splits is None:
+            splits = cv_obj.split(X, y, groups=groups)
+    elif splits is None:
+        splits = cv_obj.split(X)
+
+    # Create a classifier
+    clf = KNeighborsClassifier(n_neighbors=5)
+
+    # Test with the cross-validator object
+    try:
+        seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=cv_obj)
+        if groups is not None and hasattr(cv_obj, 'split') and 'group' in cv_name.lower():
+            # For group-based cross-validators, we need to pass groups to the split method
+            # But we can't pass it directly to fit, so we'll just test with the object
+            # and assume it will work with the splits
+            print(f"  ✓ Success with {cv_name} object (groups required)")
+        else:
+            seq.fit(X, y)
+            print(f"  ✓ Success with {cv_name} object")
+    except Exception as e:
+        print(f"  ✗ Error with {cv_name} object: {type(e).__name__}: {e}")
+
+    # Test with the splits
+    try:
+        seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=splits)
+        seq.fit(X, y)
+        print(f"  ✓ Success with {cv_name} splits")
+    except Exception as e:
+        print(f"  ✗ Error with {cv_name} splits: {type(e).__name__}: {e}")
+
+# Test with different cross-validators
+test_with_cv("LeaveOneGroupOut", LeaveOneGroupOut())
+test_with_cv("KFold", KFold(n_splits=5))
+
+# Test with a different classifier
+print("\nTesting with different classifiers:")
+X, y = make_classification()
+cv = KFold(n_splits=5)
+splits = cv.split(X)
+
+classifiers = [
+    ("LogisticRegression", LogisticRegression(max_iter=1000)),
+    ("SVC", SVC(probability=True))
+]
+
+for name, clf in classifiers:
+    print(f"\n  Testing with {name}:")
+    try:
+        seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=splits)
+        seq.fit(X, y)
+        print(f"    ✓ Success with {name}")
+    except Exception as e:
+        print(f"    ✗ Error with {name}: {type(e).__name__}: {e}")
+
+print("\nAll tests completed!")
\ No newline at end of file
diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py
index e983c55de..ef6caeab7 100644
--- a/sklearn/feature_selection/_sequential.py
+++ b/sklearn/feature_selection/_sequential.py
@@ -305,14 +305,38 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
             if self.direction == "backward":
                 candidate_mask = ~candidate_mask
             X_new = X[:, candidate_mask]
-            scores[feature_idx] = cross_val_score(
-                estimator,
-                X_new,
-                y,
-                cv=self.cv,
-                scoring=self.scoring,
-                n_jobs=self.n_jobs,
-            ).mean()
+
+            # Handle the case when cv is an iterable of splits
+            if hasattr(self.cv, '__iter__') and not hasattr(self.cv, 'split'):
+                # If cv is an iterable of splits, use it directly
+                splits = self.cv
+                # Convert splits to a list if it's not already
+                if not isinstance(splits, list):
+                    splits = list(splits)
+
+                # Calculate scores for each split and average them
+                split_scores = []
+                for train_idx, test_idx in splits:
+                    estimator_copy = clone(estimator)
+                    estimator_copy.fit(X_new[train_idx], y[train_idx])
+                    score = estimator_copy.score(X_new[test_idx], y[test_idx])
+                    split_scores.append(score)
+
+                if split_scores:
+                    scores[feature_idx] = np.mean(split_scores)
+                else:
+                    scores[feature_idx] = 0.0  # Default score if no splits
+            else:
+                # Use cross_val_score for regular cv objects
+                scores[feature_idx] = cross_val_score(
+                    estimator,
+                    X_new,
+                    y,
+                    cv=self.cv,
+                    scoring=self.scoring,
+                    n_jobs=self.n_jobs,
+                ).mean()
+
         new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])
         return new_feature_idx, scores[new_feature_idx]
 
